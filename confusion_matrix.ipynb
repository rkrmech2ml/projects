{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "83ab6283",
      "metadata": {
        "id": "83ab6283"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix,f1_score\n",
        "class Evaluation():\n",
        "    def __init__(self,ground_truth,predicted):\n",
        "        \n",
        "        self.ground_truth = ground_truth\n",
        "        self.predicted    = predicted\n",
        "        ip_matrix = np.column_stack((self.ground_truth, self.predicted))\n",
        "        c_matrix = confusion_matrix(ground_truth, predicted)\n",
        "        \n",
        "        recall = self.getRecall(c_matrix)\n",
        "        precision = self.getPrecision(c_matrix)\n",
        "        self.f1_score = f1_score(ground_truth, predicted, average='macro')\n",
        "        Accuracy = self.getAccuracy(self.ground_truth, self.predicted,c_matrix)\n",
        "\n",
        "        \n",
        "    \n",
        "    def getAccuracy(self,ground_truth, predicted,c_matrix):\n",
        "        tp = np.diag(c_matrix)\n",
        "        accuracy =tp/len(ground_truth)\n",
        "        return accuracy \n",
        "        print(accuracy) \n",
        "    \n",
        "\n",
        "    \n",
        "    def getPrecision(self,c_matrix):\n",
        "        j = 1\n",
        "        precision = []\n",
        "        for i in range(len(c_matrix)):\n",
        "            precision_val = c_matrix[i][i] / (c_matrix[i][i] + c_matrix[j][i])\n",
        "            precision  +=precision_val\n",
        "            j -= 1\n",
        "        return precision\n",
        "        print(precision)\n",
        "    \n",
        "    def getRecall(self,c_matrix):\n",
        "        j = 1\n",
        "        recall = []\n",
        "        for i in range(len(c_matrix)):\n",
        "\n",
        "            recall_val = c_matrix[i][i] / (c_matrix[i][i] + c_matrix[i][j])\n",
        "            recall  += recall_val\n",
        "            j -= 1\n",
        "        return recall\n",
        "        print(recall)\n",
        "    \n",
        "    def getF1Score(self):\n",
        "        return self.f1_score\n",
        "        print(self.f1_score)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "ground_truth = [0,1,0,0,0,1,1,0,0,1]\n",
        "predicted    = [0,0,0,1,0,1,0,1,0,0]\n",
        "        \n",
        "obj = Evaluation(ground_truth,predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e0e6a4",
      "metadata": {
        "id": "a6e0e6a4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
